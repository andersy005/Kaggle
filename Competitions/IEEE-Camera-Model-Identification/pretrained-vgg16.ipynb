{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = '/home/ubuntu/IEEE/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/ubuntu/IEEE/new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if base_dir exists, if not create it\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTC-1-M7',\n",
       " 'Motorola-X',\n",
       " 'iPhone-6',\n",
       " 'Motorola-Nexus-6',\n",
       " 'Samsung-Galaxy-Note3',\n",
       " 'iPhone-4s',\n",
       " 'Motorola-Droid-Maxx',\n",
       " 'Sony-NEX-7',\n",
       " 'LG-Nexus-5x',\n",
       " 'Samsung-Galaxy-S4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get camera list\n",
    "cameras = os.listdir(original_dataset_dir)\n",
    "cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "    train_camera_dir = os.path.join(train_dir, camera)\n",
    "    if not os.path.exists(train_camera_dir):\n",
    "        os.mkdir(train_camera_dir)\n",
    "\n",
    "    validation_camera_dir = os.path.join(validation_dir, camera)\n",
    "    if not os.path.exists(validation_camera_dir):\n",
    "        os.mkdir(validation_camera_dir)\n",
    "\n",
    "    test_camera_dir = os.path.join(test_dir, camera)\n",
    "    if not os.path.exists(test_camera_dir):\n",
    "        os.mkdir(test_camera_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_photos_names_prefix = [('HTC-1-M7', 'HTC-1-M7'),\n",
    "                              ('iPhone-4s', 'iP4s'),\n",
    "                              ('iPhone-6', 'iP6'),\n",
    "                              ('LG-Nexus-5x', 'LG5x'),\n",
    "                              ('Motorola-Droid-Maxx', 'MotoMax'),\n",
    "                              ('Motorola-Nexus-6', 'MotoNex6'),\n",
    "                              ('Motorola-X', 'MotoX'),\n",
    "                              ('Samsung-Galaxy-Note3', 'GalaxyN3'),\n",
    "                              ('Samsung-Galaxy-S4', 'GalaxyS4'),\n",
    "                              ('Sony-NEX-7', 'Nex7')]\n",
    "len(camera_photos_names_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in camera_photos_names_prefix:\n",
    "    ext1 = '.jpg'\n",
    "    ext2 = '.JPG'\n",
    "\n",
    "    fnames = []\n",
    "    for i in range(210):\n",
    "        if camera[0] != 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext1)\n",
    "\n",
    "        elif camera[0] == 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext2)\n",
    "\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(os.path.join(\n",
    "            original_dataset_dir, camera[0]), fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, camera[0]), fname)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in camera_photos_names_prefix:\n",
    "    ext1 = '.jpg'\n",
    "    ext2 = '.JPG'\n",
    "\n",
    "    fnames = []\n",
    "    for i in range(210, 240):\n",
    "        if camera[0] != 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext1)\n",
    "\n",
    "        elif camera[0] == 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext2)\n",
    "\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(os.path.join(\n",
    "            original_dataset_dir, camera[0]), fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir, camera[0]), fname)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in camera_photos_names_prefix:\n",
    "    ext1 = '.jpg'\n",
    "    ext2 = '.JPG'\n",
    "\n",
    "    fnames = []\n",
    "    for i in range(240, 275):\n",
    "        if camera[0] != 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext1)\n",
    "\n",
    "        elif camera[0] == 'Sony-NEX-7':\n",
    "\n",
    "            fnames.append('(' + camera[1] + ')' + str(i + 1) + ext2)\n",
    "\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(os.path.join(\n",
    "            original_dataset_dir, camera[0]), fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, camera[0]), fname)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training HTC-1-M7 images: 210 \n",
      "Total training Motorola-X images: 210 \n",
      "Total training iPhone-6 images: 210 \n",
      "Total training Motorola-Nexus-6 images: 210 \n",
      "Total training Samsung-Galaxy-Note3 images: 210 \n",
      "Total training iPhone-4s images: 210 \n",
      "Total training Motorola-Droid-Maxx images: 210 \n",
      "Total training Sony-NEX-7 images: 210 \n",
      "Total training LG-Nexus-5x images: 210 \n",
      "Total training Samsung-Galaxy-S4 images: 210 \n"
     ]
    }
   ],
   "source": [
    "for camera in cameras:\n",
    "    camera_dir = os.path.join(train_dir, camera)\n",
    "    print('Total training {} images: {} '.format(camera, len(os.listdir(camera_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total validation HTC-1-M7 images: 65 \n",
      "Total validation Motorola-X images: 65 \n",
      "Total validation iPhone-6 images: 65 \n",
      "Total validation Motorola-Nexus-6 images: 65 \n",
      "Total validation Samsung-Galaxy-Note3 images: 65 \n",
      "Total validation iPhone-4s images: 65 \n",
      "Total validation Motorola-Droid-Maxx images: 65 \n",
      "Total validation Sony-NEX-7 images: 65 \n",
      "Total validation LG-Nexus-5x images: 65 \n",
      "Total validation Samsung-Galaxy-S4 images: 65 \n"
     ]
    }
   ],
   "source": [
    "for camera in cameras:\n",
    "    camera_dir = os.path.join(validation_dir, camera)\n",
    "    print('Total validation {} images: {} '.format(camera, len(os.listdir(camera_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test HTC-1-M7 images: 55 \n",
      "Total test Motorola-X images: 55 \n",
      "Total test iPhone-6 images: 55 \n",
      "Total test Motorola-Nexus-6 images: 55 \n",
      "Total test Samsung-Galaxy-Note3 images: 55 \n",
      "Total test iPhone-4s images: 55 \n",
      "Total test Motorola-Droid-Maxx images: 55 \n",
      "Total test Sony-NEX-7 images: 55 \n",
      "Total test LG-Nexus-5x images: 55 \n",
      "Total test Samsung-Galaxy-S4 images: 55 \n"
     ]
    }
   ],
   "source": [
    "for camera in cameras:\n",
    "    camera_dir = os.path.join(test_dir, camera)\n",
    "    print('Total test {} images: {} '.format(camera, len(os.listdir(camera_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_base = Xception(weights='imagenet', include_top=False,\n",
    "                     input_shape = (64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 2, 2, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 10))\n",
    "    generator = datagen.flow_from_directory(\n",
    "                directory,\n",
    "                target_size=(64, 64),\n",
    "                batch_size = batch_size,\n",
    "                class_mode = 'categorical')\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Because generators yield data indefinitely in a loop, we must break after every image has been seen once.\n",
    "            break\n",
    "            \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_features, validation_labels = extract_features(validation_dir, 650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_features, test_labels = extract_features(test_dir, 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base:  30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights before freezing the conv base: ', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base:  4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights after freezing the conv base: ', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 27,565,386\n",
      "Trainable params: 12,850,698\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(224, 224),\n",
    "            batch_size = 32,\n",
    "            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 650 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_dir,\n",
    "            target_size=(224, 224),\n",
    "            batch_size = 32,\n",
    "            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              loss = 'categorical_crossentropy',\n",
    "               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 433s 9s/step - loss: 2.3417 - acc: 0.2112 - val_loss: 1.9048 - val_acc: 0.3125\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 394s 8s/step - loss: 1.9061 - acc: 0.3188 - val_loss: 2.0704 - val_acc: 0.2313\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 362s 7s/step - loss: 1.7511 - acc: 0.3745 - val_loss: 1.8606 - val_acc: 0.3187\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 377s 8s/step - loss: 1.6901 - acc: 0.3924 - val_loss: 1.6899 - val_acc: 0.4203\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 369s 7s/step - loss: 1.5927 - acc: 0.4391 - val_loss: 1.7469 - val_acc: 0.3844\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 380s 8s/step - loss: 1.5278 - acc: 0.4384 - val_loss: 1.5931 - val_acc: 0.4078\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 372s 7s/step - loss: 1.5725 - acc: 0.4469 - val_loss: 1.5847 - val_acc: 0.4516\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 376s 8s/step - loss: 1.4276 - acc: 0.5019 - val_loss: 1.6229 - val_acc: 0.4281\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 385s 8s/step - loss: 1.4237 - acc: 0.5100 - val_loss: 1.5430 - val_acc: 0.4656\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 377s 8s/step - loss: 1.4246 - acc: 0.5016 - val_loss: 1.5031 - val_acc: 0.4828\n",
      "CPU times: user 1h 16min 23s, sys: 1min 30s, total: 1h 17min 53s\n",
      "Wall time: 1h 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=50,\n",
    "            epochs=10,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained-vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 550 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/IEEE/test',\n",
    "        target_size = (224, 224),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.366279069864\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = test_datagen.flow_from_directory(\n",
    "        '/home/ubuntu/IEEE/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)  # our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict_generator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2640, 1)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "for fname in sorted(os.listdir('/home/ubuntu/IEEE/test')):\n",
    "    test_images.append(fname)\n",
    "\n",
    "test = pd.DataFrame(test_images, columns=['fname'])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0002a04_manip.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_001e31c_unalt.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00275cf_manip.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0034113_unalt.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00344b7_unalt.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname\n",
       "0  img_0002a04_manip.tif\n",
       "1  img_001e31c_unalt.tif\n",
       "2  img_00275cf_manip.tif\n",
       "3  img_0034113_unalt.tif\n",
       "4  img_00344b7_unalt.tif"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from skimage.data import imread\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
